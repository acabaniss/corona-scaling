{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban scaling and coronavirus #\n",
    "\n",
    "This notebook is a replication attempt of Stier et al.'s preprint on Arxiv [1]. This notebook brings together MSA definitions and census data to allow demographic calculations for MSAs in relation to the coronavirus outbreak. The MSAs are a county-level unit delineated by the Census Bureau (see https://www.census.gov/programs-surveys/metro-micro/about/delineation-files.html). The coronavirus outbreak data are provided by USAFacts (https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/, last downloaded March 25th, 2020 14:34 EDT).\n",
    "\n",
    ".. [1] Andrew J Stier, Marc G. Berman, and Luis M. A. Bettencourt. March 23rd, 2020. COVID-19 attack rate increases with city size. arXiv:2003.10376v1 [q-bio.PE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import key packages\n",
    "import numpy as np\n",
    "import pandas\n",
    "import datetime #the covid dataset uses datetimes as column indices\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the datasets: the MSA delineations, the ACS 2018 population estimates, and the USAFacts Coronavirus dataset\n",
    "msas = pandas.read_excel(r'data/USCensus/Delineations/list1_Sep_2018.xls',header=2)\n",
    "pop = pandas.read_excel(r'data/USCensus/Population/co-est2018-alldata.xls')\n",
    "covid = pandas.read_excel(r'data/Coronavirus/USAFacts/covid_confirmed_usafacts.xls')\n",
    "deaths = pandas.read_excel(r'data/Coronavirus/USAFacts/covid_deaths_usafacts.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some tests for exploring the data, feel free to run to get a sense of what these tables contain.\n",
    "#print(msas.iloc[0])\n",
    "#print(pop.iloc[0])\n",
    "#print(covid.iloc[0])\n",
    "#msas['CBSA Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Assemble the state, metro/micro areas, pop data, and covid cases\n",
    "data = []\n",
    "popnotfound = []\n",
    "covidnotfound = []\n",
    "covidnotincl = []\n",
    "dateStart = datetime.datetime(2020, 3, 13, 0, 0)\n",
    "dateEnd = datetime.datetime(2020, 3, 19, 0, 0) #INCLUSIVE; note this date was chosen for comparability with the arxiv preprint\n",
    "days = (dateEnd - dateStart).days+1\n",
    "\n",
    "col_names = ['CBSA','Title','MetroMicro','Pop2018','COVIDEnd','AttackRate','r']\n",
    "#We have to leave out Puerto Rico because it is not in the census data; I'm sorry!\n",
    "for cbsa in msas.loc[(msas['FIPS State Code'] != 72) & (msas.index <= 1914)]['CBSA Code'].unique():\n",
    "    #Get the MSA information\n",
    "    #cbsa = '10740' #ABQ metro for testing\n",
    "    counties = msas.loc[msas['CBSA Code'] == cbsa]\n",
    "    row = [cbsa,counties.loc[counties.index[0]]['CBSA Title'],counties.loc[counties.index[0]]['Metropolitan/Micropolitan Statistical Area']]\n",
    "    #for all state and county codes, go through and select the relevant pop data\n",
    "    pop_total = 0\n",
    "    covid_last = 0\n",
    "    covid_series = [0]*days #This stores just cases, not people who died\n",
    "    #Loop through every constituent county to get the population as well as the COVID cases\n",
    "    for s, c in zip(counties['FIPS State Code'],counties['FIPS County Code']):\n",
    "        fips = int(s*1000 + c) #str(int(s)) + '0'*(3-len(str(int(c))))+str(int(c))\n",
    "        if any((pop.STATE == int(s)) & (pop.COUNTY == int(c))):\n",
    "            pop_total += int(pop.loc[(pop.STATE == int(s)) & (pop.COUNTY == int(c))]['POPESTIMATE2018'])\n",
    "        else:\n",
    "            print(str(fips) + ' was not found in the ACS data.')\n",
    "            popnotfound.append(fips)\n",
    "        if any(fips == covid.countyFIPS):\n",
    "            covid_last += int(sum(covid.loc[(covid.countyFIPS == fips)][dateEnd]))-int(sum(deaths.loc[(deaths.countyFIPS == fips)][dateEnd]))\n",
    "            for i,d in zip(range(days),pandas.date_range(dateStart,dateEnd)):\n",
    "                covid_series[i] += int(sum(covid.loc[(covid.countyFIPS == fips)][d])) - int(sum(deaths.loc[(deaths.countyFIPS == fips)][d]))\n",
    "        else:\n",
    "            #print(str(fips) + ' was not found in the COVID data.')\n",
    "            covidnotfound.append(fips)\n",
    "    row.append(pop_total)\n",
    "    row.append(covid_last)\n",
    "    #Now calculate the r\n",
    "    if (covid_series[-1] <= 3) or (covid_series[0]<=0):\n",
    "        print(row[1] + ' had too few cases for inclusion')\n",
    "        covidnotincl.append(cbsa)\n",
    "        row.append(np.nan)\n",
    "        row.append(np.nan)\n",
    "    else:\n",
    "        #normalize the covid_series so that the March 13th data is 1\n",
    "        covid_series = [cs * 1. / covid_series[0] for cs in covid_series]\n",
    "        #run a regression\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(range(days),[np.log(cs) for cs in covid_series])\n",
    "        row.append(slope)\n",
    "        row.append(r_value)\n",
    "    data.append(row)\n",
    "df = pandas.DataFrame(data,columns=col_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.r[pandas.isna(df.r) == False])\n",
    "plt.title('Correlations are overall pretty good for the city-by-city estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the chart from figure 1a from the arxiv preprint\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "points, = ax.plot([np.log(x) for x in df.Pop2018],[np.log(y) for y in df.AttackRate],'bo')\n",
    "\n",
    "#Now run a linear regression \n",
    "#Only include those where an attack rate could be esitmated and its a Metropolitan Area (not Micro)\n",
    "which = df.index[(pandas.isna(df.AttackRate)==False) & (df.MetroMicro == 'Metropolitan Statistical Area')] \n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress([np.log(x) for x in df.Pop2018[which]],[np.log(y) for y in df.AttackRate[which]])\n",
    "line, = ax.plot([np.log(x) for x in df.Pop2018],[np.log(x)*slope + intercept for x in df.Pop2018],'k-')\n",
    "plt.xlabel('log(MSA Population)')\n",
    "plt.ylabel('log(Estimated attack rate)')\n",
    "plt.title('Coronavirus attack rate correlation with population size')\n",
    "print('Correlation: %f, p-value: %f, slope: %f' % (r_value,p_value,slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
